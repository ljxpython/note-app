# ğŸ› ï¸ æŠ€æœ¯å®ç°æ–‡æ¡£
## NoteAI - Python + AutoGen æŠ€æœ¯å®ç°æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-01-17  
**æŠ€æœ¯æ ˆ**: Python 3.12 + FastAPI + AutoGen v0.4  
**Scrum Master**: AI Scrum Master  

---

## ğŸ¯ æŠ€æœ¯æ¶æ„æ¦‚è§ˆ

### æ ¸å¿ƒæŠ€æœ¯æ ˆ
- **åç«¯æ¡†æ¶**: FastAPI + Python 3.12
- **AIæ¡†æ¶**: Microsoft AutoGen v0.4 (autogen-core + autogen-agentchat)
- **æ•°æ®åº“**: PostgreSQL (ç”¨æˆ·æ•°æ®) + MongoDB (ç¬”è®°/AIä¼šè¯) + Redis (ç¼“å­˜)
- **æ¶ˆæ¯é˜Ÿåˆ—**: Celery + Redis
- **æœç´¢å¼•æ“**: Elasticsearch
- **å®¹å™¨åŒ–**: Docker + Docker Compose
- **APIæ–‡æ¡£**: FastAPIè‡ªåŠ¨ç”Ÿæˆ + Swagger UI

### é¡¹ç›®ç»“æ„
```
noteai/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ user_service/           # ç”¨æˆ·æœåŠ¡ (Port 8001)
â”‚   â”œâ”€â”€ ai_service/             # AIæœåŠ¡ (Port 8002)
â”‚   â”œâ”€â”€ note_service/           # ç¬”è®°æœåŠ¡ (Port 8003)
â”‚   â””â”€â”€ api_gateway/            # APIç½‘å…³ (Port 8000)
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ models/                 # å…±äº«æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ config/                 # é…ç½®ç®¡ç†
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docker/                     # Dockeré…ç½®
â”œâ”€â”€ scripts/                    # éƒ¨ç½²è„šæœ¬
â””â”€â”€ requirements/               # ä¾èµ–ç®¡ç†
```

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### Pythonç¯å¢ƒè®¾ç½®
```bash
# åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python3.12 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -U pip setuptools wheel

# å®‰è£…AutoGen
pip install -U "autogen-agentchat" "autogen-ext[openai]" "autogen-core"

# å®‰è£…FastAPIå’Œå…¶ä»–ä¾èµ–
pip install fastapi uvicorn sqlalchemy psycopg2-binary
pip install motor pymongo redis celery elasticsearch
pip install pydantic python-jose[cryptography] passlib[bcrypt]
pip install pytest pytest-asyncio httpx
```

### Dockerå¼€å‘ç¯å¢ƒ
```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  # PostgreSQL - ç”¨æˆ·æ•°æ®
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: noteai_users
      POSTGRES_USER: noteai
      POSTGRES_PASSWORD: noteai_dev_pass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # MongoDB - ç¬”è®°å’ŒAIä¼šè¯
  mongodb:
    image: mongo:6
    environment:
      MONGO_INITDB_ROOT_USERNAME: noteai
      MONGO_INITDB_ROOT_PASSWORD: noteai_dev_pass
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db

  # Redis - ç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—
  redis:
    image: redis:7-alpine
    command: redis-server --requirepass noteai_dev_pass
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # Elasticsearch - æœç´¢å¼•æ“
  elasticsearch:
    image: elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

volumes:
  postgres_data:
  mongodb_data:
  redis_data:
  elasticsearch_data:
```

---

## ğŸ¤– AutoGen AIæœåŠ¡å®ç°

### AI Agentæ¶æ„è®¾è®¡
```python
# ai_service/agents/base_agent.py
from autogen_core import BaseAgent, MessageContext
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient
from typing import Dict, Any, Optional
import asyncio
import json

class NoteAIBaseAgent(BaseAgent):
    """NoteAIåŸºç¡€Agentç±»"""
    
    def __init__(self, name: str, model_config: Dict[str, Any]):
        super().__init__(name)
        self.model_client = self._create_model_client(model_config)
        self.assistant = AssistantAgent(
            name=name,
            model_client=self.model_client,
            system_message=self._get_system_message()
        )
    
    def _create_model_client(self, config: Dict[str, Any]):
        """åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯"""
        if config.get("provider") == "deepseek":
            return OpenAIChatCompletionClient(
                model=config.get("model", "deepseek-chat"),
                api_key=config.get("api_key"),
                base_url="https://api.deepseek.com"
            )
        else:
            return OpenAIChatCompletionClient(
                model=config.get("model", "gpt-4"),
                api_key=config.get("api_key")
            )
    
    def _get_system_message(self) -> str:
        """è·å–ç³»ç»Ÿæ¶ˆæ¯ï¼Œå­ç±»éœ€è¦é‡å†™"""
        return "You are a helpful AI assistant."
    
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¯·æ±‚ï¼Œå­ç±»éœ€è¦é‡å†™"""
        raise NotImplementedError
```

### æ–‡æœ¬ä¼˜åŒ–Agent
```python
# ai_service/agents/text_optimizer.py
from .base_agent import NoteAIBaseAgent
from typing import Dict, Any, List
import re

class TextOptimizerAgent(NoteAIBaseAgent):
    """æ–‡æœ¬ä¼˜åŒ–AI Agent"""
    
    def _get_system_message(self) -> str:
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

1. è¯†åˆ«å¹¶ä¿®æ­£è¯­æ³•é”™è¯¯
2. æ”¹å–„è¡¨è¾¾æ–¹å¼ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€å‡†ç¡®
3. ä¼˜åŒ–æ–‡æœ¬ç»“æ„ï¼Œæé«˜å¯è¯»æ€§
4. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒæ„æ€ä¸å˜
5. æ ¹æ®ç”¨æˆ·çš„å†™ä½œé£æ ¼åå¥½è¿›è¡Œè°ƒæ•´

è¯·å§‹ç»ˆè¿”å›JSONæ ¼å¼çš„ç»“æœï¼ŒåŒ…å«ï¼š
- optimized_text: ä¼˜åŒ–åçš„å®Œæ•´æ–‡æœ¬
- suggestions: å…·ä½“çš„ä¿®æ”¹å»ºè®®åˆ—è¡¨
- confidence: ä¼˜åŒ–è´¨é‡çš„ç½®ä¿¡åº¦(0-1)
"""
    
    async def optimize_text(self, text: str, user_style: Optional[str] = None) -> Dict[str, Any]:
        """ä¼˜åŒ–æ–‡æœ¬å†…å®¹"""
        prompt = self._build_optimization_prompt(text, user_style)
        
        try:
            result = await self.assistant.run(task=prompt)
            return self._parse_optimization_result(result.messages[-1].content)
        except Exception as e:
            return {
                "error": str(e),
                "optimized_text": text,
                "suggestions": [],
                "confidence": 0.0
            }
    
    def _build_optimization_prompt(self, text: str, user_style: Optional[str]) -> str:
        """æ„å»ºä¼˜åŒ–æç¤ºè¯"""
        prompt = f"""è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼š

åŸæ–‡ï¼š
{text}

"""
        if user_style:
            prompt += f"ç”¨æˆ·å†™ä½œé£æ ¼åå¥½ï¼š{user_style}\n"
        
        prompt += """
è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
{
    "optimized_text": "ä¼˜åŒ–åçš„å®Œæ•´æ–‡æœ¬",
    "suggestions": [
        {
            "type": "grammar|expression|structure",
            "original": "åŸå§‹ç‰‡æ®µ",
            "optimized": "ä¼˜åŒ–ç‰‡æ®µ",
            "explanation": "ä¿®æ”¹è¯´æ˜",
            "position": {"start": 0, "end": 10}
        }
    ],
    "confidence": 0.95
}
"""
        return prompt
    
    def _parse_optimization_result(self, result_text: str) -> Dict[str, Any]:
        """è§£æä¼˜åŒ–ç»“æœ"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›é»˜è®¤ç»“æ„
                return {
                    "optimized_text": result_text,
                    "suggestions": [],
                    "confidence": 0.5
                }
        except json.JSONDecodeError:
            return {
                "optimized_text": result_text,
                "suggestions": [],
                "confidence": 0.3
            }
```

### å†…å®¹åˆ†ç±»Agent
```python
# ai_service/agents/content_classifier.py
from .base_agent import NoteAIBaseAgent
from typing import Dict, Any, List

class ContentClassifierAgent(NoteAIBaseAgent):
    """å†…å®¹åˆ†ç±»AI Agent"""
    
    def _get_system_message(self) -> str:
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†ç±»åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

1. åˆ†ææ–‡æœ¬å†…å®¹çš„ä¸»é¢˜å’Œç±»å‹
2. æ ¹æ®ç°æœ‰åˆ†ç±»ä½“ç³»æ¨èæœ€åˆé€‚çš„åˆ†ç±»
3. æå–å…³é”®è¯å’Œä¸»é¢˜æ ‡ç­¾
4. è¯„ä¼°åˆ†ç±»çš„ç½®ä¿¡åº¦

è¯·å§‹ç»ˆè¿”å›JSONæ ¼å¼çš„ç»“æœã€‚
"""
    
    async def classify_content(self, content: str, existing_categories: List[Dict]) -> Dict[str, Any]:
        """åˆ†ç±»å†…å®¹"""
        prompt = self._build_classification_prompt(content, existing_categories)
        
        try:
            result = await self.assistant.run(task=prompt)
            return self._parse_classification_result(result.messages[-1].content)
        except Exception as e:
            return {
                "error": str(e),
                "suggestions": [],
                "detected_topics": [],
                "key_phrases": []
            }
    
    def _build_classification_prompt(self, content: str, categories: List[Dict]) -> str:
        """æ„å»ºåˆ†ç±»æç¤ºè¯"""
        categories_text = "\n".join([
            f"- {cat['name']}: {cat.get('description', '')}" 
            for cat in categories
        ])
        
        return f"""è¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶è¿›è¡Œåˆ†ç±»ï¼š

å†…å®¹ï¼š
{content}

ç°æœ‰åˆ†ç±»ï¼š
{categories_text}

è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
{{
    "suggestions": [
        {{
            "category_name": "åˆ†ç±»åç§°",
            "confidence": 0.92,
            "reasoning": "åˆ†ç±»ç†ç”±"
        }}
    ],
    "detected_topics": ["ä¸»é¢˜1", "ä¸»é¢˜2"],
    "key_phrases": ["å…³é”®è¯1", "å…³é”®è¯2"],
    "content_type": "æŠ€æœ¯æ–‡æ¡£|å­¦ä¹ ç¬”è®°|å·¥ä½œæ€»ç»“|åˆ›æ„æƒ³æ³•|å…¶ä»–"
}}
"""
    
    def _parse_classification_result(self, result_text: str) -> Dict[str, Any]:
        """è§£æåˆ†ç±»ç»“æœ"""
        try:
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {
                    "suggestions": [],
                    "detected_topics": [],
                    "key_phrases": [],
                    "content_type": "å…¶ä»–"
                }
        except json.JSONDecodeError:
            return {
                "suggestions": [],
                "detected_topics": [],
                "key_phrases": [],
                "content_type": "å…¶ä»–"
            }
```

---

## ğŸš€ FastAPIæœåŠ¡å®ç°

### ç”¨æˆ·æœåŠ¡ (Port 8001)
```python
# user_service/main.py
from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy.orm import Session
from passlib.context import CryptContext
from jose import JWTError, jwt
from datetime import datetime, timedelta
import os

app = FastAPI(
    title="NoteAI User Service",
    description="ç”¨æˆ·è®¤è¯å’Œç®¡ç†æœåŠ¡",
    version="1.0.0"
)

# å®‰å…¨é…ç½®
SECRET_KEY = os.getenv("JWT_SECRET_KEY", "your-secret-key")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
security = HTTPBearer()

# æ•°æ®æ¨¡å‹
from pydantic import BaseModel, EmailStr

class UserCreate(BaseModel):
    email: EmailStr
    username: str
    password: str

class UserLogin(BaseModel):
    email: EmailStr
    password: str

class UserResponse(BaseModel):
    id: str
    email: str
    username: str
    created_at: datetime
    is_active: bool

class Token(BaseModel):
    access_token: str
    token_type: str
    expires_in: int

# APIç«¯ç‚¹
@app.post("/api/v1/auth/register", response_model=UserResponse)
async def register_user(user_data: UserCreate, db: Session = Depends(get_db)):
    """ç”¨æˆ·æ³¨å†Œ"""
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
    existing_user = db.query(User).filter(
        (User.email == user_data.email) | (User.username == user_data.username)
    ).first()
    
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ç”¨æˆ·å·²å­˜åœ¨"
        )
    
    # åˆ›å»ºæ–°ç”¨æˆ·
    hashed_password = pwd_context.hash(user_data.password)
    new_user = User(
        email=user_data.email,
        username=user_data.username,
        password_hash=hashed_password
    )
    
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    
    return UserResponse.from_orm(new_user)

@app.post("/api/v1/auth/login", response_model=Token)
async def login_user(credentials: UserLogin, db: Session = Depends(get_db)):
    """ç”¨æˆ·ç™»å½•"""
    user = db.query(User).filter(User.email == credentials.email).first()
    
    if not user or not pwd_context.verify(credentials.password, user.password_hash):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="é‚®ç®±æˆ–å¯†ç é”™è¯¯"
        )
    
    # ç”ŸæˆJWT Token
    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": str(user.id)}, 
        expires_delta=access_token_expires
    )
    
    return Token(
        access_token=access_token,
        token_type="bearer",
        expires_in=ACCESS_TOKEN_EXPIRE_MINUTES * 60
    )

@app.get("/api/v1/users/profile", response_model=UserResponse)
async def get_user_profile(current_user: User = Depends(get_current_user)):
    """è·å–ç”¨æˆ·èµ„æ–™"""
    return UserResponse.from_orm(current_user)

# å·¥å…·å‡½æ•°
def create_access_token(data: dict, expires_delta: timedelta = None):
    """åˆ›å»ºJWT Token"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security),
    db: Session = Depends(get_db)
):
    """è·å–å½“å‰ç”¨æˆ·"""
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid token")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
    
    user = db.query(User).filter(User.id == user_id).first()
    if user is None:
        raise HTTPException(status_code=401, detail="User not found")
    
    return user
```

### AIæœåŠ¡ (Port 8002)
```python
# ai_service/main.py
from fastapi import FastAPI, Depends, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import redis
import json
from .agents.text_optimizer import TextOptimizerAgent
from .agents.content_classifier import ContentClassifierAgent

app = FastAPI(
    title="NoteAI AI Service",
    description="AIæ–‡æœ¬å¤„ç†å’Œåˆ†ç±»æœåŠ¡",
    version="1.0.0"
)

# Redisè¿æ¥
redis_client = redis.Redis(
    host=os.getenv("REDIS_HOST", "localhost"),
    port=int(os.getenv("REDIS_PORT", 6379)),
    password=os.getenv("REDIS_PASSWORD"),
    decode_responses=True
)

# AI Agentå®ä¾‹
model_config = {
    "provider": "deepseek",
    "model": "deepseek-chat",
    "api_key": os.getenv("DEEPSEEK_API_KEY")
}

text_optimizer = TextOptimizerAgent("text_optimizer", model_config)
content_classifier = ContentClassifierAgent("content_classifier", model_config)

# è¯·æ±‚æ¨¡å‹
class OptimizationRequest(BaseModel):
    text: str
    user_id: str
    user_style: Optional[str] = None
    optimization_type: str = "all"  # grammar, expression, structure, all

class ClassificationRequest(BaseModel):
    content: str
    user_id: str
    existing_categories: List[Dict[str, Any]] = []

# APIç«¯ç‚¹
@app.post("/api/v1/ai/optimize-text")
async def optimize_text(
    request: OptimizationRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(verify_token)
):
    """æ–‡æœ¬ä¼˜åŒ–API"""
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"optimize:{hash(request.text)}:{request.user_style}"
    cached_result = redis_client.get(cache_key)
    
    if cached_result:
        return json.loads(cached_result)
    
    try:
        # è°ƒç”¨AI Agent
        result = await text_optimizer.optimize_text(
            text=request.text,
            user_style=request.user_style
        )
        
        # ç¼“å­˜ç»“æœ
        redis_client.setex(cache_key, 1800, json.dumps(result))  # 30åˆ†é’Ÿç¼“å­˜
        
        # åå°ä»»åŠ¡ï¼šè®°å½•ä½¿ç”¨æƒ…å†µ
        background_tasks.add_task(
            log_ai_usage,
            user_id=request.user_id,
            operation="text_optimization",
            input_length=len(request.text)
        )
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AIå¤„ç†å¤±è´¥: {str(e)}")

@app.post("/api/v1/ai/classify-content")
async def classify_content(
    request: ClassificationRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(verify_token)
):
    """å†…å®¹åˆ†ç±»API"""
    cache_key = f"classify:{hash(request.content)}"
    cached_result = redis_client.get(cache_key)
    
    if cached_result:
        return json.loads(cached_result)
    
    try:
        result = await content_classifier.classify_content(
            content=request.content,
            existing_categories=request.existing_categories
        )
        
        # ç¼“å­˜ç»“æœ
        redis_client.setex(cache_key, 3600, json.dumps(result))  # 1å°æ—¶ç¼“å­˜
        
        # è®°å½•ä½¿ç”¨æƒ…å†µ
        background_tasks.add_task(
            log_ai_usage,
            user_id=request.user_id,
            operation="content_classification",
            input_length=len(request.content)
        )
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†ç±»å¤±è´¥: {str(e)}")

async def log_ai_usage(user_id: str, operation: str, input_length: int):
    """è®°å½•AIä½¿ç”¨æƒ…å†µ"""
    # è¿™é‡Œå¯ä»¥è®°å½•åˆ°æ•°æ®åº“æˆ–ç›‘æ§ç³»ç»Ÿ
    pass

async def verify_token(authorization: str = Depends(HTTPBearer())):
    """éªŒè¯JWT Token"""
    # è°ƒç”¨ç”¨æˆ·æœåŠ¡éªŒè¯Token
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨ç”¨æˆ·æœåŠ¡API
    return {"user_id": "test-user"}
```

---

## ğŸ“ ç¬”è®°æœåŠ¡å®ç° (Port 8003)

### ç¬”è®°æ•°æ®æ¨¡å‹ (MongoDB)
```python
# note_service/models.py
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
from bson import ObjectId

class PyObjectId(ObjectId):
    @classmethod
    def __get_validators__(cls):
        yield cls.validate

    @classmethod
    def validate(cls, v):
        if not ObjectId.is_valid(v):
            raise ValueError("Invalid objectid")
        return ObjectId(v)

    @classmethod
    def __modify_schema__(cls, field_schema):
        field_schema.update(type="string")

class NoteCreate(BaseModel):
    title: str
    content: str = ""
    category_id: Optional[str] = None
    tags: List[str] = []
    is_public: bool = False

class NoteUpdate(BaseModel):
    title: Optional[str] = None
    content: Optional[str] = None
    category_id: Optional[str] = None
    tags: Optional[List[str]] = None
    status: Optional[str] = None
    is_public: Optional[bool] = None

class Note(BaseModel):
    id: PyObjectId = Field(default_factory=PyObjectId, alias="_id")
    user_id: str
    title: str
    content: str
    content_html: str = ""
    excerpt: str = ""

    # å…ƒæ•°æ®
    word_count: int = 0
    character_count: int = 0
    reading_time: int = 0  # åˆ†é’Ÿ
    language: str = "zh"

    # åˆ†ç±»å’Œæ ‡ç­¾
    category_id: Optional[str] = None
    tags: List[str] = []

    # çŠ¶æ€
    status: str = "draft"  # draft, published, archived, deleted
    is_public: bool = False
    is_favorite: bool = False

    # æ—¶é—´æˆ³
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

    class Config:
        allow_population_by_field_name = True
        arbitrary_types_allowed = True
        json_encoders = {ObjectId: str}
```

### ç¬”è®°æœåŠ¡API
```python
# note_service/main.py
from fastapi import FastAPI, Depends, HTTPException, Query
from motor.motor_asyncio import AsyncIOMotorClient
from typing import List, Optional
import os
import asyncio
from datetime import datetime

app = FastAPI(
    title="NoteAI Note Service",
    description="ç¬”è®°ç®¡ç†æœåŠ¡",
    version="1.0.0"
)

# MongoDBè¿æ¥
MONGODB_URL = os.getenv("MONGODB_URL", "mongodb://localhost:27017")
client = AsyncIOMotorClient(MONGODB_URL)
database = client.noteai
notes_collection = database.notes

@app.post("/api/v1/notes", response_model=Note)
async def create_note(
    note_data: NoteCreate,
    current_user: dict = Depends(verify_token)
):
    """åˆ›å»ºç¬”è®°"""
    # å¤„ç†å†…å®¹
    content_html = await render_markdown(note_data.content)
    excerpt = generate_excerpt(note_data.content)

    note_dict = {
        "user_id": current_user["user_id"],
        "title": note_data.title,
        "content": note_data.content,
        "content_html": content_html,
        "excerpt": excerpt,
        "word_count": len(note_data.content),
        "character_count": len(note_data.content),
        "reading_time": calculate_reading_time(note_data.content),
        "category_id": note_data.category_id,
        "tags": note_data.tags,
        "is_public": note_data.is_public,
        "created_at": datetime.utcnow(),
        "updated_at": datetime.utcnow()
    }

    result = await notes_collection.insert_one(note_dict)
    note_dict["_id"] = result.inserted_id

    # å¼‚æ­¥ä»»åŠ¡ï¼šAIè‡ªåŠ¨åˆ†ç±»
    asyncio.create_task(auto_classify_note(str(result.inserted_id), note_data.content))

    return Note(**note_dict)

@app.get("/api/v1/notes", response_model=List[Note])
async def get_notes(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    category_id: Optional[str] = None,
    tags: Optional[List[str]] = Query(None),
    search: Optional[str] = None,
    current_user: dict = Depends(verify_token)
):
    """è·å–ç¬”è®°åˆ—è¡¨"""
    skip = (page - 1) * limit

    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    query = {"user_id": current_user["user_id"], "status": {"$ne": "deleted"}}

    if category_id:
        query["category_id"] = category_id

    if tags:
        query["tags"] = {"$in": tags}

    if search:
        query["$or"] = [
            {"title": {"$regex": search, "$options": "i"}},
            {"content": {"$regex": search, "$options": "i"}}
        ]

    # æ‰§è¡ŒæŸ¥è¯¢
    cursor = notes_collection.find(query).sort("updated_at", -1).skip(skip).limit(limit)
    notes = await cursor.to_list(length=limit)

    return [Note(**note) for note in notes]

@app.get("/api/v1/notes/{note_id}", response_model=Note)
async def get_note(
    note_id: str,
    current_user: dict = Depends(verify_token)
):
    """è·å–å•ä¸ªç¬”è®°"""
    note = await notes_collection.find_one({
        "_id": ObjectId(note_id),
        "user_id": current_user["user_id"]
    })

    if not note:
        raise HTTPException(status_code=404, detail="ç¬”è®°ä¸å­˜åœ¨")

    return Note(**note)

@app.put("/api/v1/notes/{note_id}", response_model=Note)
async def update_note(
    note_id: str,
    note_data: NoteUpdate,
    current_user: dict = Depends(verify_token)
):
    """æ›´æ–°ç¬”è®°"""
    update_data = {"updated_at": datetime.utcnow()}

    # åªæ›´æ–°æä¾›çš„å­—æ®µ
    for field, value in note_data.dict(exclude_unset=True).items():
        if field == "content":
            update_data["content"] = value
            update_data["content_html"] = await render_markdown(value)
            update_data["excerpt"] = generate_excerpt(value)
            update_data["word_count"] = len(value)
            update_data["character_count"] = len(value)
            update_data["reading_time"] = calculate_reading_time(value)
        else:
            update_data[field] = value

    result = await notes_collection.update_one(
        {"_id": ObjectId(note_id), "user_id": current_user["user_id"]},
        {"$set": update_data}
    )

    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="ç¬”è®°ä¸å­˜åœ¨")

    # è·å–æ›´æ–°åçš„ç¬”è®°
    updated_note = await notes_collection.find_one({"_id": ObjectId(note_id)})
    return Note(**updated_note)

@app.delete("/api/v1/notes/{note_id}")
async def delete_note(
    note_id: str,
    current_user: dict = Depends(verify_token)
):
    """åˆ é™¤ç¬”è®°ï¼ˆè½¯åˆ é™¤ï¼‰"""
    result = await notes_collection.update_one(
        {"_id": ObjectId(note_id), "user_id": current_user["user_id"]},
        {"$set": {"status": "deleted", "updated_at": datetime.utcnow()}}
    )

    if result.matched_count == 0:
        raise HTTPException(status_code=404, detail="ç¬”è®°ä¸å­˜åœ¨")

    return {"message": "ç¬”è®°å·²åˆ é™¤"}

# å·¥å…·å‡½æ•°
async def render_markdown(content: str) -> str:
    """æ¸²æŸ“Markdownä¸ºHTML"""
    import markdown
    return markdown.markdown(content)

def generate_excerpt(content: str, max_length: int = 200) -> str:
    """ç”Ÿæˆæ‘˜è¦"""
    # ç§»é™¤Markdownæ ‡è®°
    import re
    clean_content = re.sub(r'[#*`\[\]()]', '', content)
    return clean_content[:max_length] + "..." if len(clean_content) > max_length else clean_content

def calculate_reading_time(content: str) -> int:
    """è®¡ç®—é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
    words = len(content.split())
    return max(1, words // 200)  # å‡è®¾æ¯åˆ†é’Ÿ200å­—

async def auto_classify_note(note_id: str, content: str):
    """è‡ªåŠ¨åˆ†ç±»ç¬”è®°"""
    # è°ƒç”¨AIæœåŠ¡è¿›è¡Œåˆ†ç±»
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨AIæœåŠ¡API
    pass
```

---

## ğŸ³ Dockeréƒ¨ç½²é…ç½®

### æœåŠ¡Dockerfile
```dockerfile
# Dockerfile.user_service
FROM python:3.12-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements/user_service.txt .
RUN pip install --no-cache-dir -r user_service.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY user_service/ ./user_service/
COPY shared/ ./shared/

# æš´éœ²ç«¯å£
EXPOSE 8001

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "user_service.main:app", "--host", "0.0.0.0", "--port", "8001"]
```

### Docker Composeç”Ÿäº§é…ç½®
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  # APIç½‘å…³
  api-gateway:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - user-service
      - note-service
      - ai-service

  # ç”¨æˆ·æœåŠ¡
  user-service:
    build:
      context: .
      dockerfile: Dockerfile.user_service
    environment:
      - DATABASE_URL=${USER_DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
    depends_on:
      - postgres
      - redis
    deploy:
      replicas: 2

  # AIæœåŠ¡
  ai-service:
    build:
      context: .
      dockerfile: Dockerfile.ai_service
    environment:
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - REDIS_URL=${REDIS_URL}
      - MONGODB_URL=${MONGODB_URL}
    depends_on:
      - mongodb
      - redis
    deploy:
      replicas: 2

  # ç¬”è®°æœåŠ¡
  note-service:
    build:
      context: .
      dockerfile: Dockerfile.note_service
    environment:
      - MONGODB_URL=${MONGODB_URL}
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - REDIS_URL=${REDIS_URL}
    depends_on:
      - mongodb
      - elasticsearch
      - redis
    deploy:
      replicas: 2

  # æ•°æ®åº“æœåŠ¡
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      replicas: 1

  mongodb:
    image: mongo:6
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    volumes:
      - mongodb_data:/data/db
    deploy:
      replicas: 1

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    deploy:
      replicas: 1

  elasticsearch:
    image: elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    deploy:
      replicas: 1

volumes:
  postgres_data:
  mongodb_data:
  redis_data:
  elasticsearch_data:
```

---

## ğŸ§ª æµ‹è¯•é…ç½®

### æµ‹è¯•ä¾èµ–
```txt
# requirements/test.txt
pytest==7.4.3
pytest-asyncio==0.21.1
httpx==0.25.2
pytest-mock==3.12.0
factory-boy==3.3.0
faker==20.1.0
```

### æµ‹è¯•ç¤ºä¾‹
```python
# tests/test_ai_service.py
import pytest
import asyncio
from unittest.mock import Mock, patch
from ai_service.agents.text_optimizer import TextOptimizerAgent

@pytest.fixture
def mock_model_config():
    return {
        "provider": "deepseek",
        "model": "deepseek-chat",
        "api_key": "test-api-key"
    }

@pytest.fixture
def text_optimizer(mock_model_config):
    return TextOptimizerAgent("test_optimizer", mock_model_config)

@pytest.mark.asyncio
async def test_optimize_text_success(text_optimizer):
    """æµ‹è¯•æ–‡æœ¬ä¼˜åŒ–æˆåŠŸåœºæ™¯"""
    test_text = "è¿™ä¸ªç®—æ³•çš„æ•ˆç‡ä¸æ˜¯å¾ˆå¥½"

    # Mock AutoGen Assistant
    with patch.object(text_optimizer.assistant, 'run') as mock_run:
        mock_result = Mock()
        mock_result.messages = [Mock()]
        mock_result.messages[-1].content = '''
        {
            "optimized_text": "è¿™ä¸ªç®—æ³•çš„æ•ˆç‡æœ‰å¾…æå‡",
            "suggestions": [
                {
                    "type": "expression",
                    "original": "ä¸æ˜¯å¾ˆå¥½",
                    "optimized": "æœ‰å¾…æå‡",
                    "explanation": "ä½¿ç”¨æ›´ä¸“ä¸šçš„è¡¨è¾¾"
                }
            ],
            "confidence": 0.9
        }
        '''
        mock_run.return_value = mock_result

        result = await text_optimizer.optimize_text(test_text)

        assert result["optimized_text"] == "è¿™ä¸ªç®—æ³•çš„æ•ˆç‡æœ‰å¾…æå‡"
        assert len(result["suggestions"]) == 1
        assert result["confidence"] == 0.9

@pytest.mark.asyncio
async def test_optimize_text_error_handling(text_optimizer):
    """æµ‹è¯•æ–‡æœ¬ä¼˜åŒ–é”™è¯¯å¤„ç†"""
    test_text = "æµ‹è¯•æ–‡æœ¬"

    with patch.object(text_optimizer.assistant, 'run', side_effect=Exception("API Error")):
        result = await text_optimizer.optimize_text(test_text)

        assert "error" in result
        assert result["optimized_text"] == test_text
        assert result["confidence"] == 0.0
```

---

**æŠ€æœ¯å®ç°æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆ
**åŒ…å«å†…å®¹**: Python + AutoGenå®Œæ•´æŠ€æœ¯æ ˆå®ç°
**ä¸‹ä¸€æ­¥**: åˆ‡æ¢åˆ° @dev è§’è‰²å¼€å§‹ä»£ç å®ç°
